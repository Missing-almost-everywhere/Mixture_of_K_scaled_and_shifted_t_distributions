setwd("~/Home project/Home project/Mixture_of_K_scaled_and_shifted_Tdistributions")
knitr::opts_chunk$set(echo = TRUE)
# library's to Rcpp
library("Rcpp")
library("RcppArmadillo")
library("RcppGSL")
sourceCpp("compstat.cpp")
library(ClusterR)
#KMeans_rcpp #kmeans++ works well and is in Rcpp
# for fiting scaled and shifted t-distribution
library(fitdistrplus)
library(MASS)
# for paraleel gridseach in the intilasation
library(doParallel)
library(foreach)
# build function in R
library("metRology")
library("extraDistr")
#function for generating a vector of draws from a mixture T distribuations
Draw_mixture_componet <- function(Pi=c(0.2, 0.5, 0.3),
Mu=c(0,25,50),
Sigma=c(1,2,1),
Nu=c(3,4,4),
N_samples=1000){
#sample mixture componets
mixture_componoets_sample <- sample(x = 1:length(Pi), size = N_samples, replace = TRUE, prob = Pi)
draws=c(rep(0,N_samples))
for (i in 1:N_samples){
d_i=sample(x = 1:length(Pi), size = 1, replace = TRUE, prob = Pi) #draw_index = d_i
draws[i]=rt.scaled(n = 1, df = Nu[d_i], mean = Mu[d_i], sd = Sigma[d_i])
}
return(draws)
}
# itnernall function of initialation
initialize_if_na <- function(var,# variabels
K# numer of partions
) {
if (any(is.na(var))) {
return(rep(NA, K))
}
return(var)
}
# estimation of PI by taking proportion of partions
Estiame_Pi_from_partions= function(Partions_vec,K){
Pi=c(rep(0,K))
for (i in 1:K){
Mid_vec=Partions_vec==i
Pi[i]=sum(Mid_vec)/length(Partions_vec)
}
return(Pi)
}
# This is not the best parameter, but for now its better than guissing.
# it seam to work well for well seperated distribuations
Intiall_parameter_optimasation<-function(X#Data from parametasion
){
Mu<-mean(X)
variance=var(X)
fn1<-function(s){sum(-(dlst(X, df=abs(s), mu = Mu, sigma = sqrt(variance*(abs(s)-2)/abs(s)) , log = TRUE)))}
result <- optim(par = 5, fn = fn1, method = "L-BFGS-B",
lower = c(2+0.05))
Nu_val=(abs(result$par))
Sigma_val=sqrt(variance*(Nu_val-2)/Nu_val)
return(c(Mu,Sigma_val,Nu_val))
}
Intiall_parameter<-function(X,#Data in vector form
Pi=NA,#Problillaty vector
Mu=NA,# mean vector
Sigma=NA,#Sigma vector
Nu =NA, # NU vector
K # Number of distribuations
){
if(any(c(is.na(Pi),is.na(Mu),is.na(Sigma),is.na(Nu)))){
# get partions
KMeans_objet=KMeans_rcpp(as.matrix(X), clusters = K, num_init = 30, initializer = 'kmeans++')
}
if(any(is.na(Pi))){
#Estimate Pi
Pi=Estiame_Pi_from_partions(KMeans_objet$clusters,K)
}
if(any(c(is.na(Mu),is.na(Sigma),is.na(Nu)))){
#Make sure their is vector
Mu=initialize_if_na(Mu,K)
Sigma=initialize_if_na(Sigma,K)
Nu=initialize_if_na(Nu,K)
for (i in 1:K){
partin_data=X[KMeans_objet$clusters==i]
partin_parameter=Intiall_parameter_optimasation(partin_data)
if(is.na(Mu[i])){
Mu[i]=partin_parameter[1]
}
if(is.na(Sigma[i])){
Sigma[i]=partin_parameter[2]
}
if(is.na(Nu[i])){
Nu[i]=partin_parameter[3]
}
}
}
ret_obj=list(Mu = Mu,
Sigma = Sigma,
Nu=Nu,
Pi=Pi)
return(ret_obj)
}
# use kmeans to Pi estimate pi and mu
Intiall_parameter_grid=function(X,Pi,Mu,Sigma_grid,Nu_grid,K){
if(any(c(is.na(Pi),is.na(Mu)))){
# get partions
KMeans_objet=KMeans_rcpp(as.matrix(X), clusters = K, num_init = 30, initializer = 'kmeans++')
}
if(any(is.na(Pi))){
#Estimate Pi
Pi=Estiame_Pi_from_partions(KMeans_objet$clusters,K)
}
if(any(is.na(Mu))){
#Make sure their is vector
Mu=initialize_if_na(Mu,K)
for (i in 1:K){
partin_data=X[KMeans_objet$clusters==i]
if(is.na(Mu[i])){
Mu[i]=mean(partin_data)
}
}
}
#preform gridseach but only over paramters Sigma and nu
#Finding combinations
#Sigma_grid=as.numeric(seq(2,5))
#make list with comnations
Sigma_grid_combinations <- expand.grid(rep(list(Sigma_grid), K))
#makes List of list whith every combantion in the seq Sigma_grid
list_of_combinations_Sigma <- split(as.matrix(Sigma_grid_combinations), seq(nrow(Sigma_grid_combinations)))
#Nu_grid=as.numeric(seq(2,10))
Nu_grid_combinations<-expand.grid(rep(list(Nu_grid), K))
list_of_combinations_Nu <- split(as.matrix(Nu_grid_combinations), seq(nrow(Nu_grid_combinations)))
grid_for_seach=expand.grid(list_of_combinations_Sigma,list_of_combinations_Nu)
# This can be paralised but, it mean define all the functions from Rcpp in R so they can be importet into the clusters
#souch rcpp can export function to paralles so redefine functions
# # Number of cores to use
# num_cores <- detectCores() - 1 # supose to be nice to let one stand for other stuff
# # Create a cluster
# cl <- makeCluster(num_cores)
# registerDoParallel(cl)
# clusterExport(cl, c("loglikelyhood_t_mix", "X", "Pi", "Mu", "grid_for_seach"))
#
# results <- foreach(i = 1:nrow(grid_for_seach), .combine = rbind) %dopar% {
# row <- grid_for_seach[i, ]
# var1 <- as.vector(unlist((row[1])))
# var2 <-  as.vector(unlist((row[2])))#
#
# log_likelihood_val <- den_test(X, Pi, Mu, c(5,5,5), c(4,4,4)) # function can be importet to clusters so the method wont work
# c(var1 = var1, var2 = var2, log_likelihood_val = log_likelihood_val)
# }
# stopCluster(cl)
compute_log_likelihood <- function(row) {
var1 <- as.vector(unlist(row[1]))
var2 <- as.vector(unlist(row[2]))
loglikelyhood_t_mix(X, Pi, Mu, var1, var2)
}
log_likelihood_values <- sapply(1:nrow(grid_for_seach), function(i) {
compute_log_likelihood(grid_for_seach[i, ])
})
max_log_likelihood <- max(log_likelihood_values)
max_index <- which.max(log_likelihood_values)
Sigma=as.vector(unlist(grid_for_seach[max_index,]$Var1))
Nu=as.vector(unlist(grid_for_seach[max_index,]$Var2))
ret_obj=list(Mu = Mu,
Sigma = Sigma,
Nu=Nu,
Pi=Pi,
likelyhood=max_log_likelihood,
Numer_of_combination=nrow(grid_for_seach))
return(ret_obj)
}
#Kmeans is used to run make intiall partions, when Scaled shifted t distribuation is fitted on each partions.
# This method works well when the distribuations is well seperated, but not if mixture distributuin is to close.
#basically what happen if the partions is to close what happens is that partions do not look like t distribution, and can somtime even look like uniform distribution (basically far of), this make the estimation of the ustabel and sometimes lead to error, the solution is to come with some manuall inputs
EM_Mix_T_Dist<-function(X,#Data in vector form
Pi=NA,#Problillaty vector
Mu=NA,# mean vector
Sigma=NA,#Sigma vector
Nu =NA, # NU vector
K, # Number of distribuations
Clipping_vector=c(10,5,2),# Max value for clipping  for parameters (Mu,Sigma,Ni)
Max_iter=100,# maxium number of interations for the EM algorithm
alpha=0.02,# scaling for gradient decent
max_iter_gradient=3,# maxium number of times in graident for each iteratin
norm_gradient = 0.1, # stop criteria for gradient decent
Start_method_optim=T){
#Checking for intiations process
#if no argument is given for Pi , Mu , Sigma and NU is given then a gues is made
if(Start_method_optim==T){
start_para=Intiall_parameter(X,Pi,Mu,Sigma,Nu,K)
}
else{
start_para=Intiall_parameter_grid(X,Pi,Mu,Sigma_grid=as.numeric(seq(1,15,2)),as.numeric(seq(2,10,2)),K)
}
Pi=start_para$Pi
Mu=start_para$Mu
Sigma=start_para$Sigma
Nu=start_para$Nu
if(any(c(is.na(Pi),is.na(Mu),is.na(Sigma),is.na(Nu)))){
print("The intilasaions failed")
return(NA)
}
#Run EM
EM_partion=EM_t_distribution(X,Pi,Mu,Sigma,Nu,Clipping_vector = Clipping_vector,Max_iter=Max_iter,alpha=alpha,max_iter_gradient=max_iter_gradient,norm_gradient = norm_gradient)
#Make return object
likelyhood=likelyhood_t_mix(X,EM_partion[,4],EM_partion[,1],EM_partion[,2],EM_partion[,3])
loglikelyhood=loglikelyhood_t_mix(X,EM_partion[,4],EM_partion[,1],EM_partion[,2],EM_partion[,3])
AIC=2*K-2*loglikelyhood
BIC=K*log(length(X))-2*loglikelyhood
ret_obj=list(Mu = EM_partion[,1],
Sigma = EM_partion[,2],
Nu=EM_partion[,3],
Pi=EM_partion[,4],
AIC=AIC,
BIC=BIC,
likelyhood=likelyhood,
loglikelyhood=loglikelyhood,
weights=Weights_of_X(X,EM_partion[,4],EM_partion[,1],EM_partion[,2],EM_partion[,3]))
return(ret_obj)
}
#code for visualasation
library(ggplot2)
Plot_mix_t_distribution <- function(X,Pi,Mu,Sigma,Nu,bins=30){
plot_fun<-function(x){sapply(x,function(x){Mix_T_density_x(x,Pi,Mu,Sigma,Nu)})}
plot <- ggplot(data.frame(X), aes(x = X)) +
geom_histogram(aes(y = ..density..), bins = bins, color = "black", alpha = 0.7) +
stat_function(fun = plot_fun, geom = "line",color="red")+
labs(title = "Histogram with Mixture of t-Distributions", x = "X", y = "Density") +
theme_minimal()
return(plot)
}
# test
draws=Draw_mixture_componet()
model<-EM_Mix_T_Dist(draws,K=3)
Plot_mix_t_distribution(draws,model$Pi,model$Mu,model$Sigma,model$Nu,bins=50)
